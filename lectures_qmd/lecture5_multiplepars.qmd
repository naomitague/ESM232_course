---
title: "Informal Sensitvity2"
format:
  revealjs:
    theme: solarized
    resources: ["img/"]
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)

library(purrr)

library(ggpubr)

library(here)
```

## Combined sensivitivity analysis

-   *eff*

-   *ethresh*

Sample from both of them - each time we run the model we vary both of the parameters at the same time

Then create plots to show the impact of parameter uncertainty

## Combined parameter sensitivity

Two possible approaches

-   *for*
-   *pmap* from purrr (when you want to vary more than one input to the model)

## using *pmap* {.scrollable}

```{r secondsensitivity, echo=TRUE}
# generate samples for both parameters
nsamples <- 300
deviation <- 0.15
base_thresh <- 10000
ethresh <- runif(
  min = base_thresh - deviation * base_thresh,
  max = base_thresh + deviation * base_thresh, n = nsamples
)

eff <- rnorm(mean = 0.6, sd = 0.1, n = nsamples)

# put samples together
parms <- cbind.data.frame(eff, ethresh)

# use pmap
# takes function name and then names of all parameters that don't change
results <- parms %>% pmap(solarpv,
  area = 0.1,
  solar = sierraczosolar, clr = "green",
  eunit = "W", g = FALSE, etype = "direct"
)

results[[1]]
length(results)

# now we can extract results from the list as above
mean_elect <- map_df(results, `[`, c("mean"))
# and we can add the parameter values for each run
mean_elect <- cbind.data.frame(mean_elect, parms)

# plot - pick one of the 2 parameter as a color
# try switching which parameter used for color

p1 <- ggplot(mean_elect, aes(ethresh, mean, col = eff)) +
  geom_point(cex = 2) +
  labs(y = "Mean Annual Electricity W", x = "Threshold Radiation (kJ/m2)  \n above which energy production is more efficient")
p1

p2 <- ggplot(mean_elect, aes(eff, mean, col = ethresh)) +
  geom_point(cex = 2) +
  labs(y = "Mean Annual Electricity W", x = "Efficiency")
p2


# extract annual
# plot total uncertainty due to both parameters
tmp <- map_df(results, `[`, c("annual"))
solar_annual_elect <- as.data.frame(tmp$annual$year)
colnames(solar_annual_elect) <- "year"
solar_annual_elect$elect <- tmp$annual$elect

ggplot(solar_annual_elect, aes(year, elect, group = year)) +
  geom_boxplot() +
  labs(y = "Electricity generated in W")

# save this model output for next lecture
save(solar_annual_elect, file = here("Data/annual_elect_solar.rda"))
```

# Sensitivity to two different parameters

-   note how one parameter **eff** overshadows the response to *"ethresh*

-   note the linear response to *eff*

## Additional notes {.scrollable}

Using a *For* Loop for sensitivity analysis

```{r}
# using a for loop
# start by creating a data structures to hold results, separate
# for scenario mean and annual values
mean_elect_for <- rep(NA, times = nsamples)
# for annual we need rows as years, columns for samples
years <- unique(sierraczosolar$year)
annual_elect_for <- as.data.frame(matrix(ncol = nsamples, nrow = length(years)))
annual_elect_for$year <- years


for (i in 1:nsamples) {
  res <- solarpv(
    area = 0.1, solar = sierraczosolar,
    clr = "green", eunit = "W", g = FALSE, etype = "direct",
    ethresh = parms$ethresh[i],
    eff = parms$eff[i]
  )

  annual_elect_for[, i] <- res$annual$elect
  mean_elect_for[i] <- res$mean
}

# plot
me <- cbind.data.frame(mean = mean_elect_for, parms)
ggplot(me, aes(eff, mean, col = ethresh)) +
  geom_point(cex = 2) +
  labs(y = "Mean Annual Electricity W", x = "Efficiency")

tmp <- annual_elect_for %>% pivot_longer(cols = -c(year))

# get rid of that pesky first year
tmp <- subset(tmp, tmp$year > 1944)

ggplot(tmp, aes(as.factor(year), value)) +
  geom_boxplot() +
  labs(y = "Mean Annual Electricity W", x = "Year")
```

```{r}
ggarrange(p1, p2)
```

# Expanding on Sensitivity Analysis

-   why this is useful
-   two contexts
    -   variation in parameters is a scenario
    -   variation in parameter is uncertainty

Real world examples Quiz Think of a research question, and imagine you are using a model to answer it - you don't have to know the details of the model - but think of a parameter that you might want to vary to see how it influences model outputs- Note if its due to uncertainty in that parameter or because you are exploring scenarios

# ASSIGNMENT 2 Almond Yields

Lobell et al., 2006 used data to build models of tree crop yield for California that captured how climate variation (place and time) might influence yield

-   Yield anomaly

-   Climate variables

Assumptions...as you work think about what these are...

# Assignment

For this assignment you will work in *pairs*

Your goal is to implement a simple model of almond yield anomaly response to climate

-   Inputs: daily times series of minimum, maximum daily temperatures and precipitation

-   Outputs: maximum, minimum and mean yield anomoly for a input time series

The Lobell et al. 2006 paper will be the source for the transfer function that you will use in your model; specifically look at the equations in table 2.

# What you will do - Model Set Up

1.  Draw diagram to represent your model - how it will translate inputs to outputs, with parameters that shape the relationship between inputs an outputs - on your diagram list what your inputs, parameters and outputs are with units

2.  Implement your diagram as an R function

Here are some ideas to think though. The climate data is going to need to be processed (e.g note that the model uses climate data from a particular month - you have ALL of the climate as daily data). Here are two possible model outlines to follow

● Almond_model \<- function(clim_var1, clim_var2, parameters){……}

● Almond_model \<- function(clim, parameters){……}

The first example is where the climate variables are separately input into the function - climate data is processed beforehand as part of model set up

The second is where a climate data frame is the input to the function and you extract the useful data from it as part of the model.

You can pick which option you prefer (or try both) If you want a coding challenge, you could create a model that works for any crop

# Run the model

3.  Run your model for the **clim.txt** data that is posted on Canvas,

**clim.txt** has the following columns

these 4 columns tell you when climate observations were made

-   *day*
-   *month*
-   *year*
-   *wy* (water year)

the next 3 columns are the climate observations

-   maximum (*tmax_c*) daily temperature
-   minimum (*tmin_c*) daily temperature
-   precipitation (*precip*) on that day in mm

# check your work

I will tell you that

-   the maximum almond yield anomaly should be approximately 1920 ton/acre
-   the lowest almond yield anomaly should be approximately -0.027 ton/acre
-   the mean almond yield anomaly should be approximately 182 ton/acre

# Notes

We will build on this in next Thursday's class

-   There are always multiple ways to code something in R;

-   Remember that we want to strive for our code being as simple and streamline as possible.

-   Style counts.

    -   Make sure you choose meaningful variable names and add comments.
    -   Include comments at the top of the function to tell the user what the inputs/outputs are and their units and format.

# What to hand in on Canvas

Two separate files (or a link to a repository with these files)

1.  a R file that has your function definition
2.  a Rmarkdown file that includes your conceptual model (embed as picture) and shows how you applied the function to the test climate data (*clim.txt*)

# Grading Rubric

Conceptual model (20 pts)

-   a clear diagram that corresponds with your R function (10 pts)
-   inputs and output and parameters shown on the diagram (10 pts)

R Implementation (30 pts)

-   correct function implementation (\*.R file) (10 pts)
-   application of the function to **clim.txt** (in Rmarkdown file) (10 pts)
-   coding practices (clear documentation, informative variables names) (10 pts)
